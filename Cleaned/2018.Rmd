---
title: "Data Cleaning Report for FBI 2018"
author: "Min Lin"
date: "2021/03/18"
header-includes:
  - \usepackage[labelfont=bf,textfont=md]{caption}  
  - \usepackage{float}
  - \usepackage{enumerate}
  - \setlength{\parskip}{1em}
  - \usepackage{indentfirst} 
  - \usepackage{amsmath}
output:
  rmdformats::readthedown:
    toc: 2
fontsize: 12pt
geometry: margin=1in
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(warning = FALSE,fig.align='center',fig.pos="H")
```

```{r, message=FALSE}
library(tidyverse)
```
![](data-science-explore.png) 

# Import

```{r}
# only need to change the path
path <- "C:\\Users\\Min\\OneDrive\\UConn\\Spring 2021\\BIST 5225_Data Management and Programming in R and SAS\\Group Assignment\\Crime_by_State\\2018.xls"
# skip titles. In "2018.xls", there are three rows for useless titles. 
fbi2018 <- readxl::read_excel(path, skip = 3) 
```

In "2018.xls", the first three rows are titles. 

1. "Table 5": useless
2. "Crime in the United States": useless
3. "by State, 2018": the only useful information is "2018", but it has been captured by the name of our RData `fbi2018`.

Note that there are three columns have no name: 3rd, 14th, and 15th. By looking the data, we know that the 14th and the 15th are empty columns. So remove them, and rename the 3rd. 

Also, we notice that after the 506th row are footnotes. 

```{r}
fbi2018 <- fbi2018[1:506, 1:13]
```

The footnotes are copied here for future reference. 

> __Footnotes__  
1. The violent crime figures include the offenses of murder, rape (revised definition), robbery, and aggravated assault.  
2. The figures shown in this column for the offense of rape were estimated using the revised Uniform Crime Reporting (UCR) definition of rape. See data declaration for further explanation.	  
3. Includes offenses reported by the Metro Transit Police and the Arson Investigation Unit of the District of Columbia Fire and Emergency Medical Services.  	
4. Limited data for 2018 were available for Iowa.  
5. Agencies within this state submitted rape data according to the legacy UCR definition of rape.  
__NOTE__:  Although arson data are included in the trend and clearance tables, sufficient data are not available to estimate totals for this offense.  Therefore, no arson data are published in this table.				

We need to deal with footnotes 2, 3, and 5. 
		
```{r}
# Columns names. I use "index" for the third column. 
names(fbi2018)  <- c("State","Area", "index", "Population", "ViolentCrimeRevised", 
          "Murder", "RapeRevised", "Robbery", "AggravatedAssault", 
          "PropertyCrime", "Burglary", "LarcenyTheft",	"MotorTheft")
```

All columns are named in the same style except that the name of the 3rd column begins with a lower letter ("index"). From footnote 2, the Rape column is in accordance with the revised definition. For comparability with previous years, especially those before 2014, we should emphasize the difference by using "RapeRevised". 

```{r}
fbi2018
```


# Tidy 
## Prepare ID and pivoting index
First of all, we need to identify the ID that uniquely defines a row. In our datasets, ID = {State, Area}. The State column contains 52 different values: 50 states along with Washington, D.C. and Puerto Rico. 
```{r}
fbi2018_1 <- fbi2018 %>% 
        # Replace NA in the "State" column. 
        # Every NA is filled by the first non-NA value on its above
        fill(State, .direction = "down") %>% 
        # since State has been fixed, grouped by it
        group_by(State) %>% 
        # within each state, fill for Area
        # grouped by State to prevent the NA of an Area from being filled 
        #       by values from the previous state
        fill(Area, .direction = "down") %>% 
        # modify values of index for pivot_wider (very important)
        # we will use the three values of index 
        #       to convert the data within each ID to a wider version
        mutate(
                Area = if_else(Area == "Total", "State Total", Area),
                index = case_when(
                        index == "Area actually reporting"             ~ "act",
                        index %in% c("Estimated total", 
                                     "Rate per 100,000 inhabitants")   ~ "est",
                        TRUE                                           ~ "popu" # NA -> "popu"
                )
        ) %>% ungroup()
```
As can see from `fbi2018_1`, we have filled in all NA in ID = {State, Area} and have explicitly specified the pivoting index. Before pivoting wider the columns from index to the last, let's first nest the table by State. We expect that within each state there are three areas and that within each area there are three indexes. But it that true?

```{r}
fbi2018_1 %>% group_nest(State)
```
Clearly it's not the case. The data column does not always contain a $9\times 12$ tibble. For example, let's look at Alaska:
```{r}
fbi2018_1 %>% group_nest(State) %>% pull(data) %>% .[[2]] # Alaska is the second state
```
__Note that implicit missing happens here: there are no explicit NA in the values of "index"; instead, the rows just do not appear.__ The rows are missing because the actually reporting area = 1, resulting in nonexistence of estimated total. We have to impute the estimated total, but not now. R has limited ability to deal with rows. We will be back to this point after pivoting.  

## Change values of State to propery case and trim ending digits
```{r}
state <- fbi2018_1 %>% pull(State)
state[str_detect(state, "\\d$")] %>% unique # ends with a digit
```
```{r}
fbi2018_1$State <- state %>% str_remove_all("\\d") %>% str_to_title()
fbi2018_1$State %>% unique # nice! 50 states + DC + Puerto Rico
```
## Pivot wider
```{r}
fbi2018_2 <- fbi2018_1 %>% 
        pivot_wider(names_from = index, values_from = Population:MotorTheft) 
fbi2018_2 %>% print(width = Inf)
```
Each previous column from Population to MotorTheft now has three siblings, ending with "_popu", "_act", and "_est", respectively. That's why we need to replace NA by "popu" when defining `fbi2018_1`. For Population, we keep "_popu" and "_act"; for others, we keep "_act" and "_est". The selection of columns can be done by matching the suffixes. 

```{r}
fbi2018_3 <- fbi2018_2 %>%
        rename(Population = Population_popu) %>%
        mutate(
                AreaActuallyReporting = round(as.numeric(Population_act), 3), # three digits
                .after = Area
        ) %>% select(
                -Population_est, 
                -Population_act,
                # we have renamed Population_popu, so simply drop all columns ending with "_popu"
                -ends_with("_popu")  
        )
# deal with "None" and NA is Population
# all "None" with AreaActuallyReporting NA
fbi2018_3 %>% filter(is.na(Population) | Population == "None") %>% print(width = Inf)
fbi2018_3 %>% filter(is.na(Population))

fbi2018_3$Population <- replace_na(fbi2018_3$Population, "0")  

fbi2018_3 <- fbi2018_3 %>% 
        # Population contains "None"; remove those rows 
        # also, before pivoting, Population is a character because of the appearance of "None"
        filter(Population != "None") %>% 
        mutate(Population = as.numeric(Population)) 
```
## Impute NA in est
As mentioned before, there are implicit missing in the dataset. Pivoting wider makes it explicit and automatically replaces missing elements by NA's. However, before filling NA in est by corresponding act, we need to be very cautious. 
```{r}
fbi2018_3 %>% filter(Area != "State Total") %>% map_dbl(~ sum(is.na(.x))) 
```
It appears that the number of NA is either 0 or 45, and that all act columns contain no NA. That's great! But we have to check another issue: whether or not the NA in est is always associated with AreaActuallyReporting = 1. It's possible that the NA are caused by some mysterious effects. 

```{r}
fbi2018_3 %>% filter(Area != "State Total") %>% 
        filter(AreaActuallyReporting %>% near(1)) %>% 
        select(ends_with("_est")) %>% 
        map_dbl(~ sum(is.na(.x)))
```
Hooray! 
```{r}
# Actually can be replaced by tidyr::complete() -> tidyr::fill() workflow before pivoting.
# But I have no idea how to expand the dataset. 
impute_est <- function(.tbl) {
        # To fill NA row-wise, we first have to obtain sub-tibbles
        #       that consist of all numeric columns. 
        # Then we can treat them as matrices. 
        suppressWarnings(suppressMessages(require(zoo)))
        non_dbl <- .tbl %>% select(!where(is_numeric))
        non_dbl %>% bind_cols(
                .tbl %>% select(where(is_numeric)) %>% 
                apply(1, zoo::na.locf) %>% 
                t() %>% 
                as_tibble()
        )
}

impute <- (fbi2018_3$AreaActuallyReporting == 1) %>% replace_na(FALSE)
sum(impute) # correct
fbi2018_4 <- fbi2018_3

fbi2018_4[impute, ] <- fbi2018_3[impute, ] %>% impute_est()
fbi2018_4[impute, ] %>% complete.cases() %>% all
```

# Split 

```{r}
fbi2018_act <- fbi2018_4 %>% 
        select(State:Population, ends_with("_act")) %>% 
        rename_with(~ str_remove(.x, "_act"), ends_with("_act"))
        

fbi2018_est <- fbi2018_4 %>% 
        select(State:Population, ends_with("_est")) %>% 
        rename_with(~ str_remove(.x, "_est"), ends_with("_est"))

fbi2018_est %>% filter(Area != "State Total") %>% complete.cases() %>% all

save(fbi2018_act, fbi2018_est, file = "tidy_2018.RData")
```

# Further work
We may wrap helper functions to make the "customers" happy. For example, calculate the "Rate per 100,000 inhabitants" for each state based on `fbi2018_est`:
```{r}
rate_per_100k <- function(.tbl) {
        .tbl %>% group_by(State) %>% 
                summarize(across(Population:MotorTheft, sum)) %>% 
        mutate(across(ViolentCrimeRevised:MotorTheft, ~ round(.x / Population * 1e5, 1)))
}

rate_per_100k(fbi2018_est) %>% knitr::kable(format.args = list(big.mark = ","))
```





